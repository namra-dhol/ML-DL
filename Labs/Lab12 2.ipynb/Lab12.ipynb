{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: PyTorch \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.9.6' requires the notebook and jupyter package.\n",
      "\u001b[1;31mInstall 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: GPU/Device Agnostic Code\n",
    "**Goal:** Write code that runs on CPU, CUDA, or MPS (Mac) automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "sample_input = torch.randn(1, 10).to(device)\n",
    "type(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1961,  2.2492,  1.1180,  0.7724,  0.3377, -0.7044,  0.1754,  0.8937,\n",
       "         -0.9713, -0.1360]], device='mps:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: MNIST Project \n",
    "Step 1: What is MNIST & Downloading Data\n",
    "\n",
    "Concept: MNIST is the \"Hello World\" of Machine Learning. It contains 70,000 images of handwritten digits (0-9).\n",
    "\n",
    "The Goal: Teach the computer to look at a grid of pixels and say \"That is a 7\".\n",
    "\n",
    "The Data: Each image is grayscale and exactly 28×28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# transform=ToTensor() converts the image (0-255) to a Torch Tensor (0.0-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing One Image & Understanding Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display one Image in MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"This is a number {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation for the Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept: We are building a Linear (Feed-Forward) Network,\n",
    "\n",
    "A Linear Layer consists of neurons in a single vertical line.\n",
    "\n",
    "Our image is a square grid (28×28).\n",
    "\n",
    "The Division: We must \"cut\" the image row by row and stack them into one long line.\n",
    "\n",
    "The Calculation:\n",
    "\n",
    "Height×Width=Total Input Features\n",
    "28×28=784\n",
    "So, our Input Layer must have 784 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture (1 Input, 1 Hidden, 1 Output\n",
    "The Concept: We will build the simplest standard network.\n",
    "\n",
    "Input Layer (784): Receives the pixels.\n",
    "\n",
    "Hidden Layer (128): The \"brain\" that learns shapes (loops, lines). We pick 128 because it's enough to learn but not too big.\n",
    "\n",
    "Output Layer (10): The final decision. We have 10 digits (0-9), so we need 10 output scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 128), \n",
    "            nn.ReLU(),# Activation \n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "model = SimpleNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Batch Size (The Stack)\n",
    "\n",
    "The Concept: Think of the model like a teacher grading exams.\n",
    "\n",
    "Batch Size = 1: The teacher grades 1 exam, updates the grade book, then picks up the next exam. (Too slow).\n",
    "\n",
    "Batch Size = 64: The teacher picks up a stack of 64 exams, grades them all at once, and updates the grade book one time for the whole stack. (Much faster).\n",
    "\n",
    "We use DataLoader to create these \"stacks\" for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 -- 157\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create stacks\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(train_loader),\"--\",len(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    # Epoch Loop - Train for multiple epochs\n",
    "    num_epochs = 5\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "        \n",
    "        for batch_No, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            loss = loss_fn(output, target)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()  # Clear old calculations\n",
    "            loss.backward()        # Calculate gradients\n",
    "            optimizer.step()       # Update weights\n",
    "            \n",
    "            if batch_No % 100 == 0:\n",
    "                print(f\"Batch {batch_No}: Loss = {loss.item():.4f}\")\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} completed!\")\n",
    "\n",
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss = 2.2587\n",
      "Batch 100: Loss = 0.4718\n",
      "Batch 200: Loss = 0.2364\n",
      "Batch 300: Loss = 0.3395\n",
      "Batch 400: Loss = 0.1946\n",
      "Batch 500: Loss = 0.3256\n",
      "Batch 600: Loss = 0.1262\n",
      "Batch 700: Loss = 0.2901\n",
      "Batch 800: Loss = 0.4627\n",
      "Batch 900: Loss = 0.0775\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.6%\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            prediction = output.argmax(dim=1) \n",
    "            \n",
    "            correct += (prediction == target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print(f\"Test Accuracy: {accuracy:.1%}\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
